{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BOW.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSPbElq4VH1RACdBwq6Mja",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/6ma6X/nn4nlp-code/blob/master/BOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J4K_eNGVDgG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ylXDO8iVO-7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BoW(torch.nn.Module):\n",
        "    def __init__(self, nwords, ntags): # nwords: 単語数, ntags: タグ数\n",
        "        super(BoW, self).__init__()\n",
        "\n",
        "        \"\"\" variables \"\"\"\n",
        "        type = torch.FloatTensor\n",
        "        use_cuda = torch.cuda.is_available()\n",
        "\n",
        "        if use_cuda:\n",
        "            type = torch.cuda.FloatTensor\n",
        "\n",
        "        self.bias = Variable(torch.zeros(ntags),\n",
        "                             requires_grad=True).type(type)\n",
        "         # ntags の数で初期化\n",
        "\n",
        "        \"\"\" layers \"\"\"\n",
        "        self.embedding = nn.Embedding(nwords, ntags)\n",
        "        # nwords 個の埋め込み表現、それぞれの埋め込みの次元数は ntags 個\n",
        "\n",
        "        # initialize the weights with xavier uniform (Glorot, X. & Bengio, Y. (2010))\n",
        "        nn.init.xavier_uniform_(self.embedding.weight)\n",
        "\n",
        "\n",
        "    def forward(self, words):\n",
        "        emb = self.embedding(words)\n",
        "        out = torch.sum(emb, dim=0) + self.bias # size(out) = N\n",
        "        # BoW では単純に埋め込みの和をとって bias を足す\n",
        "        out = out.view(1, -1) # size(out) = 1 x N\n",
        "        # 1 * N のベクトルに\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzZiCP_eXYET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "import time\n",
        "import random\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBx-28rwXxxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Functions to read in the corpus\n",
        "w2i = defaultdict(lambda: len(w2i))\n",
        "t2i = defaultdict(lambda: len(t2i))\n",
        "UNK = w2i[\"<unk>\"]\n",
        "def read_dataset(filename):\n",
        "    with open(filename, \"r\") as f:\n",
        "        for line in f:\n",
        "            tag, words = line.lower().strip().split(\" ||| \")\n",
        "            yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n",
        "\n",
        "# Read in the data\n",
        "train = list(read_dataset(\"train.txt\"))\n",
        "w2i = defaultdict(lambda: UNK, w2i)\n",
        "dev = list(read_dataset(\"test.txt\"))\n",
        "nwords = len(w2i)\n",
        "ntags = len(t2i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpF7DCpcYT_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "df5b77fb-804f-4e58-c804-9286d30aa446"
      },
      "source": [
        "!head -n 10 train.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 ||| The Rock is destined to be the 21st Century 's new `` Conan '' and that he 's going to make a splash even greater than Arnold Schwarzenegger , Jean-Claud Van Damme or Steven Segal .\n",
            "4 ||| The gorgeously elaborate continuation of `` The Lord of the Rings '' trilogy is so huge that a column of words can not adequately describe co-writer\\/director Peter Jackson 's expanded vision of J.R.R. Tolkien 's Middle-earth .\n",
            "3 ||| Singer\\/composer Bryan Adams contributes a slew of songs -- a few potential hits , a few more simply intrusive to the story -- but the whole package certainly captures the intended , er , spirit of the piece .\n",
            "2 ||| You 'd think by now America would have had enough of plucky British eccentrics with hearts of gold .\n",
            "3 ||| Yet the act is still charming here .\n",
            "4 ||| Whether or not you 're enlightened by any of Derrida 's lectures on `` the other '' and `` the self , '' Derrida is an undeniably fascinating and playful fellow .\n",
            "4 ||| Just the labour involved in creating the layered richness of the imagery in this chiaroscuro of madness and light is astonishing .\n",
            "3 ||| Part of the charm of Satin Rouge is that it avoids the obvious with humour and lightness .\n",
            "4 ||| a screenplay more ingeniously constructed than `` Memento ''\n",
            "3 ||| `` Extreme Ops '' exceeds expectations .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWlqohAwaMhA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "751169fe-672d-45c7-9cb8-11d9f4efa63a"
      },
      "source": [
        "train[:3] # (単語のインデックス, 評価(タグ)) のタプル の配列"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[([1,\n",
              "   2,\n",
              "   3,\n",
              "   4,\n",
              "   5,\n",
              "   6,\n",
              "   1,\n",
              "   7,\n",
              "   8,\n",
              "   9,\n",
              "   10,\n",
              "   11,\n",
              "   12,\n",
              "   13,\n",
              "   14,\n",
              "   15,\n",
              "   16,\n",
              "   9,\n",
              "   17,\n",
              "   5,\n",
              "   18,\n",
              "   19,\n",
              "   20,\n",
              "   21,\n",
              "   22,\n",
              "   23,\n",
              "   24,\n",
              "   25,\n",
              "   26,\n",
              "   27,\n",
              "   28,\n",
              "   29,\n",
              "   30,\n",
              "   31,\n",
              "   32,\n",
              "   33],\n",
              "  0),\n",
              " ([1,\n",
              "   34,\n",
              "   35,\n",
              "   36,\n",
              "   37,\n",
              "   11,\n",
              "   1,\n",
              "   38,\n",
              "   37,\n",
              "   1,\n",
              "   39,\n",
              "   13,\n",
              "   40,\n",
              "   3,\n",
              "   41,\n",
              "   42,\n",
              "   15,\n",
              "   19,\n",
              "   43,\n",
              "   37,\n",
              "   44,\n",
              "   45,\n",
              "   46,\n",
              "   47,\n",
              "   48,\n",
              "   49,\n",
              "   50,\n",
              "   51,\n",
              "   9,\n",
              "   52,\n",
              "   53,\n",
              "   37,\n",
              "   54,\n",
              "   55,\n",
              "   9,\n",
              "   56,\n",
              "   33],\n",
              "  1),\n",
              " ([57,\n",
              "   58,\n",
              "   59,\n",
              "   60,\n",
              "   19,\n",
              "   61,\n",
              "   37,\n",
              "   62,\n",
              "   63,\n",
              "   19,\n",
              "   64,\n",
              "   65,\n",
              "   66,\n",
              "   26,\n",
              "   19,\n",
              "   64,\n",
              "   67,\n",
              "   68,\n",
              "   69,\n",
              "   5,\n",
              "   1,\n",
              "   70,\n",
              "   63,\n",
              "   71,\n",
              "   1,\n",
              "   72,\n",
              "   73,\n",
              "   74,\n",
              "   75,\n",
              "   1,\n",
              "   76,\n",
              "   26,\n",
              "   77,\n",
              "   26,\n",
              "   78,\n",
              "   37,\n",
              "   1,\n",
              "   79,\n",
              "   33],\n",
              "  0)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhfoUtDdYY7L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5be9b435-bb11-43b9-9c16-a4e846bc76f7"
      },
      "source": [
        "w2i[\"destined\"] # 単語からインデックスへの対応付け"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-EwbeH8Ygcv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6336acae-5c79-4121-f061-29b22870401c"
      },
      "source": [
        "nwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18648"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkUBCi9OYxsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "61aec1df-8c8e-4bb4-e8ff-3348c337c8f9"
      },
      "source": [
        "ntags"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IClZzI3tYyUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# モデルの初期化\n",
        "\n",
        "model = BoW(nwords, ntags)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters()) # 最適化手法"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iq1zRygZGFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "type = torch.LongTensor # FloatTensor は 32bit 浮動小数、LongTensor は 64bit 浮動小数\n",
        "use_cuda = torch.cuda.is_available()\n",
        "\n",
        "if use_cuda:\n",
        "    type = torch.cuda.LongTensor\n",
        "    model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYxqZBJ5Z_BJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72ae05cf-0ab4-4568-d826-f975d890f0d5"
      },
      "source": [
        "use_cuda"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlOt4Sh5aACN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2122b146-10bd-43a6-a32b-ea0b08b449cf"
      },
      "source": [
        "for ITER in range(100):\n",
        "    # Perform training\n",
        "    random.shuffle(train)\n",
        "    train_loss = 0.0\n",
        "    start = time.time()\n",
        "    for words, tag in train:\n",
        "        words = torch.tensor(words).type(type)\n",
        "        tag = torch.tensor([tag]).type(type)\n",
        "        scores = model(words)\n",
        "        loss = criterion(scores, tag)\n",
        "        train_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (\n",
        "                ITER, train_loss/len(train), time.time()-start))\n",
        "    # Perform testing\n",
        "    test_correct = 0.0\n",
        "    for words, tag in dev:\n",
        "        words = torch.tensor(words).type(type)\n",
        "        scores = model(words)[0].detach().cpu().numpy()\n",
        "        predict = np.argmax(scores)\n",
        "        if predict == tag:\n",
        "            test_correct += 1\n",
        "    print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iter 0: train loss/sent=0.1049, time=6.25s\n",
            "iter 0: test acc=0.3814\n",
            "iter 1: train loss/sent=0.0998, time=6.46s\n",
            "iter 1: test acc=0.3828\n",
            "iter 2: train loss/sent=0.0958, time=6.45s\n",
            "iter 2: test acc=0.3828\n",
            "iter 3: train loss/sent=0.0913, time=6.67s\n",
            "iter 3: test acc=0.3765\n",
            "iter 4: train loss/sent=0.0880, time=6.69s\n",
            "iter 4: test acc=0.3796\n",
            "iter 5: train loss/sent=0.0837, time=6.30s\n",
            "iter 5: test acc=0.3792\n",
            "iter 6: train loss/sent=0.0806, time=6.50s\n",
            "iter 6: test acc=0.3796\n",
            "iter 7: train loss/sent=0.0772, time=6.87s\n",
            "iter 7: test acc=0.3756\n",
            "iter 8: train loss/sent=0.0742, time=6.68s\n",
            "iter 8: test acc=0.3738\n",
            "iter 9: train loss/sent=0.0710, time=6.86s\n",
            "iter 9: test acc=0.3715\n",
            "iter 10: train loss/sent=0.0680, time=6.49s\n",
            "iter 10: test acc=0.3760\n",
            "iter 11: train loss/sent=0.0654, time=6.36s\n",
            "iter 11: test acc=0.3697\n",
            "iter 12: train loss/sent=0.0628, time=6.35s\n",
            "iter 12: test acc=0.3742\n",
            "iter 13: train loss/sent=0.0603, time=6.54s\n",
            "iter 13: test acc=0.3724\n",
            "iter 14: train loss/sent=0.0582, time=6.74s\n",
            "iter 14: test acc=0.3692\n",
            "iter 15: train loss/sent=0.0564, time=6.54s\n",
            "iter 15: test acc=0.3701\n",
            "iter 16: train loss/sent=0.0541, time=6.36s\n",
            "iter 16: test acc=0.3706\n",
            "iter 17: train loss/sent=0.0522, time=6.63s\n",
            "iter 17: test acc=0.3701\n",
            "iter 18: train loss/sent=0.0502, time=6.74s\n",
            "iter 18: test acc=0.3701\n",
            "iter 19: train loss/sent=0.0485, time=6.63s\n",
            "iter 19: test acc=0.3679\n",
            "iter 20: train loss/sent=0.0468, time=6.58s\n",
            "iter 20: test acc=0.3692\n",
            "iter 21: train loss/sent=0.0454, time=6.67s\n",
            "iter 21: test acc=0.3674\n",
            "iter 22: train loss/sent=0.0436, time=6.35s\n",
            "iter 22: test acc=0.3674\n",
            "iter 23: train loss/sent=0.0424, time=6.26s\n",
            "iter 23: test acc=0.3643\n",
            "iter 24: train loss/sent=0.0408, time=6.37s\n",
            "iter 24: test acc=0.3656\n",
            "iter 25: train loss/sent=0.0395, time=6.39s\n",
            "iter 25: test acc=0.3679\n",
            "iter 26: train loss/sent=0.0382, time=6.40s\n",
            "iter 26: test acc=0.3656\n",
            "iter 27: train loss/sent=0.0370, time=6.27s\n",
            "iter 27: test acc=0.3670\n",
            "iter 28: train loss/sent=0.0357, time=6.41s\n",
            "iter 28: test acc=0.3661\n",
            "iter 29: train loss/sent=0.0345, time=6.23s\n",
            "iter 29: test acc=0.3661\n",
            "iter 30: train loss/sent=0.0335, time=6.31s\n",
            "iter 30: test acc=0.3638\n",
            "iter 31: train loss/sent=0.0324, time=6.53s\n",
            "iter 31: test acc=0.3633\n",
            "iter 32: train loss/sent=0.0314, time=6.60s\n",
            "iter 32: test acc=0.3652\n",
            "iter 33: train loss/sent=0.0303, time=6.36s\n",
            "iter 33: test acc=0.3647\n",
            "iter 34: train loss/sent=0.0294, time=6.70s\n",
            "iter 34: test acc=0.3633\n",
            "iter 35: train loss/sent=0.0284, time=6.80s\n",
            "iter 35: test acc=0.3611\n",
            "iter 36: train loss/sent=0.0278, time=6.36s\n",
            "iter 36: test acc=0.3620\n",
            "iter 37: train loss/sent=0.0269, time=6.78s\n",
            "iter 37: test acc=0.3611\n",
            "iter 38: train loss/sent=0.0259, time=6.82s\n",
            "iter 38: test acc=0.3597\n",
            "iter 39: train loss/sent=0.0252, time=7.07s\n",
            "iter 39: test acc=0.3615\n",
            "iter 40: train loss/sent=0.0244, time=6.53s\n",
            "iter 40: test acc=0.3615\n",
            "iter 41: train loss/sent=0.0235, time=6.66s\n",
            "iter 41: test acc=0.3593\n",
            "iter 42: train loss/sent=0.0229, time=6.42s\n",
            "iter 42: test acc=0.3629\n",
            "iter 43: train loss/sent=0.0223, time=6.68s\n",
            "iter 43: test acc=0.3584\n",
            "iter 44: train loss/sent=0.0216, time=6.35s\n",
            "iter 44: test acc=0.3620\n",
            "iter 45: train loss/sent=0.0209, time=6.58s\n",
            "iter 45: test acc=0.3561\n",
            "iter 46: train loss/sent=0.0203, time=6.53s\n",
            "iter 46: test acc=0.3552\n",
            "iter 47: train loss/sent=0.0197, time=6.47s\n",
            "iter 47: test acc=0.3597\n",
            "iter 48: train loss/sent=0.0192, time=6.26s\n",
            "iter 48: test acc=0.3561\n",
            "iter 49: train loss/sent=0.0186, time=6.24s\n",
            "iter 49: test acc=0.3566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6b4e293e275c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuRsu1Qjc_hS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}